
# ğŸ  House Price Prediction - Kaggle Competition

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **Kaggleì˜ House Prices - Advanced Regression Techniques** ëŒ€íšŒë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
ëª©í‘œëŠ” ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ **ì£¼íƒ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ìµœì í™”**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” **ë‘ ê°€ì§€ ë…¸íŠ¸ë¶(`house_price.ipynb`, `house_price_add.ipynb`)ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ê°œì„ **í•˜ì˜€ìŠµë‹ˆë‹¤.

- **`house_price.ipynb`**: ê¸°ë³¸ì ì¸ ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ë§ ìˆ˜í–‰ (Baseline Model)
- **`house_price_add.ipynb`**: Feature Engineering ì¶”ê°€, ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°, XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì ìš©

---

## ğŸ—‚ ë°ì´í„° ì„¤ëª…

- **train.csv**: ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ (1460ê°œ ìƒ˜í”Œ)
- **test.csv**: ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
- **sample_submission.csv**: Kaggle ì œì¶œ í˜•ì‹ ì˜ˆì‹œ

---

## ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ (Preprocessing)

### 1ï¸âƒ£ **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**

- `GarageType`, `BsmtQual` ë“± **ë²”ì£¼í˜• ë³€ìˆ˜ â†’ 'None'ìœ¼ë¡œ ëŒ€ì²´**
- `LotFrontage`, `GarageYrBlt`, `MasVnrArea` ë“± **ìˆ˜ì¹˜í˜• ë³€ìˆ˜ â†’ ì¤‘ì•™ê°’(median)ìœ¼ë¡œ ëŒ€ì²´**
- `Electrical` ë³€ìˆ˜ **ìµœë¹ˆê°’(mode)ìœ¼ë¡œ ëŒ€ì²´**
- ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì œê±° (`PoolQC`, `MiscFeature`, `Alley`, `Fence`)

### 2ï¸âƒ£ **Feature Engineering** (`house_price_add.ipynb`ì—ì„œ ì¶”ê°€ ê°œì„ )

- `BuildingAge` ìƒì„± (í˜„ì¬ ì—°ë„ - `YearBuilt`)
- `Remodeled` ë³€ìˆ˜ ì¶”ê°€ (`YearBuilt` vs `YearRemodAdd`)
- ë¡œê·¸ ë³€í™˜ ì ìš© (`Log_SalePrice`)
- **VIF(ë‹¤ì¤‘ê³µì„ ì„±) ì œê±°** ë° PCA ì ìš© (`TotalLivingArea` â†’ `PCA_LivingArea`)
- **ì´ìƒì¹˜ ì œê±°** (IQRì„ í™œìš©í•˜ì—¬ ê·¹ë‹¨ê°’ ì œì™¸)

---

## ğŸ“Š ëª¨ë¸ í•™ìŠµ (Model Training)

### 1ï¸âƒ£ **Baseline Model (`house_price.ipynb`)**

- **Linear Regression**
- **RandomForest Regressor**
- **XGBoost Regressor**

### 2ï¸âƒ£ **ê³ ê¸‰ ëª¨ë¸ (`house_price_add.ipynb`)**

- Feature Engineering ì ìš© í›„ ì¬í•™ìŠµ
- **êµì°¨ ê²€ì¦ ì ìš© (K-Fold)ë¡œ ëª¨ë¸ í‰ê°€**
- **XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¶”ê°€ ì ìš©**

### 3ï¸âƒ£ **XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (`house_price_add.ipynb`)**

- **GridSearchCV**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
- **ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš© í›„ ëª¨ë¸ ì¬í•™ìŠµ**

```python
param_grid = {
    "n_estimators": [300, 500, 1000],
    "learning_rate": [0.01, 0.05, 0.1],
    "max_depth": [3, 6, 9],
    "subsample": [0.6, 0.8, 1.0],
    "colsample_bytree": [0.6, 0.8, 1.0]
}
```

---

## ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (Evaluation)

- **RMSE(Log(SalePrice)) ê¸°ì¤€ ì„±ëŠ¥ ë¹„êµ**| Model             | RMSE               |
  | ----------------- | ------------------ |
  | Linear Regression | 0.155              |
  | Random Forest     | 0.139              |
  | XGBoost           | **0.129**    |
  | Tuned XGBoost     | **0.120** âœ… |

---

## ğŸ“¤ Kaggle ì œì¶œ (Submission)

```python
def create_submission(model, X_test, test_df, model_name):
    y_pred = model.predict(X_test)
    y_pred = np.expm1(y_pred)  # ë¡œê·¸ ë³€í™˜ ë³µì›

    submission = pd.DataFrame({"Id": test_df["Id"], "SalePrice": y_pred})
    file_name = f"submission_{model_name}.csv"
    submission.to_csv(file_name, index=False)

    print(f"âœ… {model_name} ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_name}")

create_submission(best_xgb_model, X_test_preprocessed, test_df, "Tuned_XGBoost")
```

- `submission_Tuned_XGBoost.csv` íŒŒì¼ì„ **Kaggleì— ì—…ë¡œë“œ**í•˜ì—¬ í‰ê°€ ê²°ê³¼ í™•ì¸

---

## ğŸ’» ì‹¤í–‰ ë°©ë²•

### 1ï¸âƒ£ **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**

```bash
pip install pandas numpy scikit-learn xgboost seaborn matplotlib
```

### 2ï¸âƒ£ **Jupyter Notebook ì‹¤í–‰**

```bash
jupyter notebook
```

- `house_price.ipynb` ì‹¤í–‰ â†’ **Baseline ëª¨ë¸ í‰ê°€**
- `house_price_add.ipynb` ì‹¤í–‰ â†’ **Feature Engineering + XGBoost íŠœë‹ ì ìš©**
- ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ í›„ **Kaggleì— ì œì¶œ**

---
