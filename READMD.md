# ğŸ¡ ë¯¸êµ­ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ í”„ë¡œì íŠ¸

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ë¯¸êµ­ ì£¼íƒ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

- **ë°ì´í„°ì…‹**: Kaggleì˜ `House Prices - Advanced Regression Techniques`
- **ëª©í‘œ ë³€ìˆ˜**: `SalePrice` (ë¡œê·¸ ë³€í™˜ëœ ê°’ ì‚¬ìš©)
- **ì‚¬ìš©í•œ ê¸°ë²•**: ë°ì´í„° ì „ì²˜ë¦¬, Feature Engineering, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ëª¨ë¸ í‰ê°€ ë° êµì°¨ê²€ì¦
- **ìµœì¢… ì˜ˆì¸¡ ëª¨ë¸**: `XGBoost Regressor`

## ğŸ“‚ ë°ì´í„° ì„¤ëª…

- `train.csv`: í•™ìŠµ ë°ì´í„° (1460ê°œ ìƒ˜í”Œ, 80ê°œ íŠ¹ì„±)
- `test.csv`: ì˜ˆì¸¡ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° (1459ê°œ ìƒ˜í”Œ, 80ê°œ íŠ¹ì„±)
- `sample_submission.csv`: ì˜ˆì¸¡ ê²°ê³¼ ì œì¶œ í˜•ì‹

## âš™ï¸ í”„ë¡œì íŠ¸ ì‹¤í–‰ ë°©ë²•

### 1ï¸âƒ£ **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**

í”„ë¡œì íŠ¸ ì‹¤í–‰ì„ ìœ„í•´ ì•„ë˜ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.

```bash
pip install pandas numpy seaborn matplotlib scikit-learn xgboost
```

### 2ï¸âƒ£ **Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**

```bash
python house_price_prediction.py
```

ë˜ëŠ” Jupyter Notebookì—ì„œ ì‹¤í–‰ ê°€ëŠ¥

---

## ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬

1. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**

   - ë²”ì£¼í˜• ë³€ìˆ˜ â†’ `'None'`ìœ¼ë¡œ ëŒ€ì²´ (`GarageType`, `BsmtQual` ë“±)
   - ìˆ˜ì¹˜í˜• ë³€ìˆ˜ â†’ ì¤‘ì•™ê°’ ëŒ€ì²´ (`LotFrontage`, `GarageYrBlt`, `MasVnrArea` ë“±)
   - `GarageYrBlt`ê°€ ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •
   - ìµœë¹ˆê°’ ëŒ€ì²´ (`Electrical` ë³€ìˆ˜)
2. **Feature Engineering**

   - ë¡œê·¸ ë³€í™˜ (`SalePrice`, ì™œë„ê°€ í° ë³€ìˆ˜)
   - ìƒˆë¡œìš´ ë³€ìˆ˜ ìƒì„± (`TotalSF = TotalBsmtSF + 1stFlrSF + 2ndFlrSF`)
   - ë‹¤ì¤‘ê³µì„ ì„±(VIF)ì´ ë†’ì€ ë³€ìˆ˜ ì œê±°
3. **ë°ì´í„° ì¸ì½”ë”© ë° í‘œì¤€í™”**

   - ë²”ì£¼í˜• ë³€ìˆ˜ â†’ `OneHotEncoding`
   - ìˆ˜ì¹˜í˜• ë³€ìˆ˜ â†’ `StandardScaler` ì ìš©

---

## ğŸ—ï¸ ëª¨ë¸ êµ¬ì¶• ë° í‰ê°€

| ëª¨ë¸                        | RMSE    |
| --------------------------- | ------- |
| **Linear Regression** | `XXX` |
| **Random Forest**     | `XXX` |
| **XGBoost**           | `XXX` |

### 1ï¸âƒ£ ëª¨ë¸ë³„ í‰ê°€ ì§€í‘œ

- **RMSE (Root Mean Squared Error) ì‚¬ìš©**
- **K-Fold Cross Validation ì ìš©** (5-Fold)

### 2ï¸âƒ£ ìµœì  ëª¨ë¸ (`XGBoost`)

```python
xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6, random_state=42)
xgb_model.fit(X_train_preprocessed, y_train)
```

---

## ğŸ“¤ Kaggle ì œì¶œ íŒŒì¼ ìƒì„±

```python
def create_submission(model, X_test, test_df, model_name):
    """ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  Kaggle ì œì¶œ íŒŒì¼ ìƒì„± """
    y_pred = model.predict(X_test)
    y_pred = np.expm1(y_pred)
    submission = pd.DataFrame({"Id": test_df["Id"], "SalePrice": y_pred})
    file_name = f"submission_{model_name}.csv"
    submission.to_csv(file_name, index=False)
    print(f"âœ… {model_name} ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_name}")
```

ìµœì  ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ì œì¶œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

---

## ğŸ“Œ ê²°ë¡ 

- `XGBoost`ê°€ ê°€ì¥ ë‚®ì€ RMSEë¥¼ ê¸°ë¡í•˜ì—¬ ìµœì  ëª¨ë¸ë¡œ ì„ ì •ë¨
- Feature Engineeringì„ í†µí•´ ì¼ë¶€ ë³€ìˆ˜ ì¶”ê°€ (`TotalSF` ë“±)
- ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ 

âœ… **ì¶”ê°€ ê°œì„  ê°€ëŠ¥ì„±**: ëª¨ë¸ ì•™ìƒë¸”(Stacking, Blending) ë˜ëŠ” ë” ì •êµí•œ Feature Engineering í™œìš© ê°€ëŠ¥

ğŸš€ **Kaggle ì œì¶œ í›„ ê²°ê³¼ í™•ì¸ í•„ìˆ˜!**

https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/submissions#

![ì£¼íƒ ê°€ê²© ì˜ˆì¸¡](images/screenshot.png)
